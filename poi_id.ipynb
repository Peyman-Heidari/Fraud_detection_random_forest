{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Fraud Detection using Email and Financial Data\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives.\n",
    "\n",
    "The goal of this project is to use  email (text) and financial data to construct a predictive model that could identify an individual as a person of interest (poi). The [Enron corpus](https://www.cs.cmu.edu/~./enron/) was made public by the US Federal Energy Regulatory Comission during its investgiation of Enron, which comprised email and financial data of 146 individuals mostly in senior management positions. The data has been widely used for various machine learning problems. However, there is value in the mentioned analysis for potential use to identify similar cases in other companies or for spam filtering application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, all needed packages and functions are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( \"../tools/\" )\n",
    "sys.path.append( \"../enron_mail_20110402/\" )\n",
    "sys.path.append( \"../emails_by_address/\" )\n",
    "import math\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from poi_email_addresses import poiEmails\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Make a list of email addresses of persons of interest (poi)\n",
    "poi_emails = poiEmails()\n",
    "emails = []\n",
    "for name in data_dict:\n",
    "    if data_dict[name]['email_address']!='NaN':\n",
    "        emails.append(data_dict[name]['email_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Make a list of all names of the individuals to remove from\n",
    "### the email data (signature or mentions) to stop unrealistic performance.\n",
    "names = []\n",
    "for name in data_dict:\n",
    "    name = re.sub('[^a-zA-Z \\n\\.]', ' ', name)\n",
    "    name = name.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "    name = re.sub(' +', ' ', name)\n",
    "    name = name.strip()\n",
    "    name = name.lower()\n",
    "    name_components = name.split(\" \")\n",
    "    names.extend(name_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_it(word):\n",
    "    \"\"\" input a word and receive the stemmed word\n",
    "        \"\"\"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed_word = stemmer.stem(word)\n",
    "    return stemmed_word\n",
    "\n",
    "def parseOutText(f):\n",
    "    \"\"\" given an opened email file f, parse out all text below the\n",
    "        metadata block at the top, remove stopwords and add stemming.\n",
    "        and return a list that contains all the words\n",
    "        in the email.\n",
    "        \"\"\"\n",
    "    f.seek(0)  ### go back to beginning of file.\n",
    "    all_text = f.read()\n",
    "\n",
    "    ### split off metadata\n",
    "    content = all_text.split(\"X-FileName:\")\n",
    "    words = \"\"\n",
    "    if len(content) > 1:\n",
    "        ### remove punctuation\n",
    "        text_string = content[1].translate(string.maketrans(\"\", \"\"), string.punctuation)\n",
    "\n",
    "        ### preprocessing\n",
    "        text_string = re.sub('[^a-zA-Z \\n\\.]', ' ', text_string)\n",
    "        text_string = text_string.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "        text_string = re.sub(' +', ' ', text_string)\n",
    "        text_string = text_string.lower()\n",
    "        text_string = text_string.strip()\n",
    "        words = text_string.split(\" \")\n",
    "\n",
    "        ### split the text string into individual words,remove stopwords stem each word,\n",
    "        ### and append the stemmed word to words.\n",
    "        sw = stopwords.words('english')\n",
    "        filtered_words = [word for word in words if word not in sw]\n",
    "        filtered_words = [word for word in filtered_words if word not in names]\n",
    "        stemmed_words = [stem_it(word) for word in filtered_words]\n",
    "        stemmed_words_pasted = \" \".join(stemmed_words)\n",
    "\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Construct a list of stemmed words in emails sent from \n",
    "### each email address.\n",
    "\n",
    "from_data = []\n",
    "word_database = []\n",
    "\n",
    "for email in emails:\n",
    "    temp_counter = 0\n",
    "    word_data = []\n",
    "    from_email = 'emails_by_address/from_'+email+'.txt'\n",
    "    # Do not take in financial data of an individual \n",
    "    # if email is not available.\n",
    "    try:\n",
    "        from_person = open(from_email, \"r\")\n",
    "    except:\n",
    "        continue\n",
    "    for path in from_person:\n",
    "        if temp_counter < 4:\n",
    "            #temp_counter += 1\n",
    "            path = os.path.join('..', path[:-1])\n",
    "            email_txt = open(path, \"r\")\n",
    "            txt = parseOutText(email_txt)\n",
    "            word_data.extend(txt)\n",
    "    email_txt.close()\n",
    "    word_data_pasted = \" \".join(word_data)\n",
    "    word_database.append(word_data_pasted)\n",
    "    from_data.append(email)\n",
    "    from_person.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Save (Pickle) email data and sender data for fast load.\n",
    "pickle.dump( word_database, open(\"word_database.pkl\", \"w\") )\n",
    "pickle.dump( from_data, open(\"from_data.pkl\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the email data and sender data.\n",
    "word_database = pickle.load(open(\"word_database.pkl\", \"r\") )\n",
    "from_data = pickle.load(open(\"from_data.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Select what features to start with\n",
    "\n",
    "all_features =  ['salary', 'to_messages', 'deferral_payments', 'total_payments',\n",
    "                 'exercised_stock_options', 'bonus', 'restricted_stock',\n",
    "                 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value',\n",
    "                 'expenses', 'loan_advances', 'from_messages', 'other',\n",
    "                 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income',\n",
    "                 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Extract the data from the dictionary and save it\n",
    "### a panda dataframe\n",
    "database_dict = defaultdict(list)\n",
    "for name in data_dict:\n",
    "    if (data_dict[name]['email_address']!='NaN') and (data_dict[name]['email_address'] in from_data):\n",
    "        for feature in all_features:\n",
    "            if data_dict[name][feature]=='NaN':\n",
    "                database_dict[feature].append(None)\n",
    "            else:\n",
    "                database_dict[feature].append(data_dict[name][feature])\n",
    "                \n",
    "database_numerical = pd.DataFrame(database_dict)\n",
    "database_numerical['poi'] = database_numerical['poi'].map({True:1, False:0})\n",
    "database_numerical = database_numerical.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "database_numerical['all_messages'] = database_numerical['from_messages']+database_numerical['to_messages']\n",
    "database_numerical['all_poi_messages'] = database_numerical['from_this_person_to_poi']+\\\n",
    "                                        database_numerical['from_poi_to_this_person']\n",
    "database_numerical['poi_to_all_ratio'] = database_numerical['all_poi_messages']/database_numerical['all_messages']\n",
    "database_numerical['total_payments_log'] = (database_numerical['total_payments']+1e-3).apply(math.log)\n",
    "database_numerical['salary_log'] = (database_numerical['salary']+1e-3).apply(math.log)\n",
    "database_numerical['bonus_log'] = (database_numerical['bonus']+1e-3).apply(math.log)\n",
    "database_numerical['total_stock_value_log'] = (database_numerical['total_stock_value']+1e-3).apply(math.log)\n",
    "database_numerical['exercised_stock_options_log'] = (database_numerical['exercised_stock_options']+1e-3).apply(math.log)\n",
    "database_numerical['loan_advances_log'] = (database_numerical['loan_advances']+1e-3).apply(math.log)\n",
    "database_numerical['director_fees_log'] = (database_numerical['director_fees']+1e-3).apply(math.log)\n",
    "database_numerical['restricted_stock_log'] = abs(database_numerical['restricted_stock']+1e-3).apply(math.log)\n",
    "database_numerical['deferral_payments_log'] = (database_numerical['deferral_payments']+1e-3).apply(math.log)\n",
    "database_numerical['total_payments_sqrt'] = (database_numerical['total_payments']).apply(math.sqrt)\n",
    "database_numerical['salary_sqrt'] = (database_numerical['salary']).apply(math.sqrt)\n",
    "database_numerical['bonus_sqrt'] = (database_numerical['bonus']).apply(math.sqrt)\n",
    "database_numerical['total_stock_value_sqrt'] = (database_numerical['total_stock_value']).apply(math.sqrt)\n",
    "database_numerical['exercised_stock_options_sqrt'] = (database_numerical['exercised_stock_options']).apply(math.sqrt)\n",
    "database_numerical['loan_advances_sqrt'] = (database_numerical['loan_advances']).apply(math.sqrt)\n",
    "database_numerical['director_fees_sqrt'] = (database_numerical['director_fees']).apply(math.sqrt)\n",
    "database_numerical['restricted_stock_sqrt'] = abs(database_numerical['restricted_stock']).apply(math.sqrt)\n",
    "database_numerical['deferral_payments_sqrt'] = (database_numerical['deferral_payments']).apply(math.sqrt)\n",
    "database_numerical['total_payments_squared'] = (database_numerical['total_payments']).apply(lambda x:x**2)\n",
    "database_numerical['salary_squared'] = (database_numerical['salary']).apply(lambda x:x**2)\n",
    "database_numerical['bonus_squared'] = (database_numerical['bonus']).apply(lambda x:x**2)\n",
    "database_numerical['total_stock_value_squared'] = (database_numerical['total_stock_value']).apply(lambda x:x**2)\n",
    "database_numerical['exercised_stock_options_squared'] = (database_numerical['exercised_stock_options']).apply(lambda x:x**2)\n",
    "database_numerical['loan_advances_squared'] = (database_numerical['loan_advances']).apply(lambda x:x**2)\n",
    "database_numerical['director_fees_squared'] = (database_numerical['director_fees']).apply(lambda x:x**2)\n",
    "database_numerical['restricted_stock_squared'] = (database_numerical['restricted_stock']).apply(lambda x:x**2)\n",
    "database_numerical['deferral_payments_sqrd'] = (database_numerical['deferral_payments']).apply(lambda x:x**2)\n",
    "\n",
    "### Substitute 0 instead of NaN\n",
    "database_numerical = database_numerical.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### split the data into training and test datasets.\n",
    "features_train, features_test,labels_train,\\\n",
    "labels_test = train_test_split(word_database, from_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "### Use Tfidf to vectorize the email data\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.2,\n",
    "                             stop_words='english')\n",
    "features_train_tfidf = vectorizer.fit_transform(features_train)\n",
    "features_test_tfidf  = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Perform encoding on the poi vaiable\n",
    "### 0:non-poi and 1:poi\n",
    "\n",
    "def label_encoder(labels):\n",
    "    labels_enconded =[]\n",
    "    for email in labels:\n",
    "        if email in poi_emails: labels_enconded.append(1)\n",
    "        else:labels_enconded.append(0)\n",
    "    return labels_enconded\n",
    "    \n",
    "labels_enconded = label_encoder(from_data)\n",
    "labels_train_enconded = label_encoder(labels_train)\n",
    "labels_test_enconded = label_encoder(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "4\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print sum(labels_enconded)\n",
    "print sum(labels_test_enconded)\n",
    "print len(labels_enconded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 14 points in the data set, 14 in the training data set and 4 in the test dataset. \n",
    "#### Overal, 86 samples (poi and non-poi) are avaible with email data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOPPER MICHAEL J\n",
      "michael.kopper@enron.com\n",
      "FASTOW ANDREW S\n",
      "andrew.fastow@enron.com\n",
      "YEAGER F SCOTT\n",
      "scott.yeager@enron.com\n",
      "HIRKO JOSEPH\n",
      "joe.hirko@enron.com\n"
     ]
    }
   ],
   "source": [
    "### Check if poi are avaialable with financial data but no email data\n",
    "for name in data_dict:\n",
    "    if data_dict[name]['poi']==True and\\\n",
    "    data_dict[name]['email_address'] not in from_data:\n",
    "        print name\n",
    "        print data_dict[name]['email_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Test classifier based on data needed for feature selection and evaluations later\n",
    "def classifier_tester(clf, features, labels, folds = 1000):\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "        \n",
    "    return f1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### This function is the pipeline that performs feature selection\n",
    "### The approach is a bit different from the normal approach and \n",
    "### using sklearn's pipeline was not possible\n",
    "### RandomForestClassifier is used here after iterations with other algorithms.\n",
    "### The same procedure will be repeated after feature selection with more comments.\n",
    "\n",
    "def feature_selection_pipeline(features_train_tfidf,labels_train_enconded,\\\n",
    "                               percentile, n_components, max_depth, n_estimators):\n",
    "    selector = SelectPercentile(f_classif, percentile=percentile)\n",
    "    selector.fit(features_train_tfidf, labels_train_enconded)\n",
    "    features_train_selected = selector.transform(features_train_tfidf)\n",
    "    features_test_selected  = selector.transform(features_test_tfidf)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(features_train_selected.toarray())\n",
    "    features_train_selected = pca.transform(features_train_selected.toarray())\n",
    "    features_test_selected = pca.transform(features_test_selected.toarray())\n",
    "    data_base_train_tfidf = pd.DataFrame(features_train_selected)\n",
    "    data_base_test_tfidf = pd.DataFrame(features_test_selected)\n",
    "    data_base_train_tfidf['email_address'] = labels_train\n",
    "    data_base_test_tfidf['email_address'] = labels_test\n",
    "    database_numerical_train = database_numerical[database_numerical['email_address']\\\n",
    "                                                  .isin(data_base_train_tfidf['email_address'])]\n",
    "    database_numerical_test = database_numerical[database_numerical['email_address']\\\n",
    "                                                 .isin(data_base_test_tfidf['email_address'])]\n",
    "    data_base_train_tfidf = data_base_train_tfidf.set_index(['email_address'])\n",
    "    data_base_test_tfidf = data_base_test_tfidf.set_index(['email_address'])\n",
    "    database_numerical_train = database_numerical_train.set_index(['email_address'])\n",
    "    database_numerical_test = database_numerical_test.set_index(['email_address'])\n",
    "    database_train = database_numerical_train.join(data_base_train_tfidf)\n",
    "    database_test = database_numerical_test.join(data_base_test_tfidf)\n",
    "    train_labels = database_train['poi'].values\n",
    "    test_labels = database_test['poi'].values\n",
    "    database_train = database_train.drop('poi', axis=1).as_matrix()\n",
    "    database_test = database_test.drop('poi', axis=1).as_matrix()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(database_train)\n",
    "    database_train = scaler.transform(database_train)\n",
    "    database_test = scaler.transform(database_test)\n",
    "    clf_rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=max_depth, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=n_estimators, n_jobs=1, oob_score=False, random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "    f1 = classifier_tester(clf_rf, database_train, train_labels, folds = 200)\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.92000\tPrecision: 0.94898\tRecall: 0.46500\tF1: 0.62416\tF2: 0.51782\n",
      "\tTotal predictions: 1400\tTrue positives:   93\tFalse positives:    5\tFalse negatives:  107\tTrue negatives: 1195\n",
      "\n",
      "=======================new best 0.624161073826 10 40 2 5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.91286\tPrecision: 0.95349\tRecall: 0.41000\tF1: 0.57343\tF2: 0.46275\n",
      "\tTotal predictions: 1400\tTrue positives:   82\tFalse positives:    4\tFalse negatives:  118\tTrue negatives: 1196\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.94071\tPrecision: 0.96063\tRecall: 0.61000\tF1: 0.74618\tF2: 0.65804\n",
      "\tTotal predictions: 1400\tTrue positives:  122\tFalse positives:    5\tFalse negatives:   78\tTrue negatives: 1195\n",
      "\n",
      "=======================new best 0.746177370031 10 40 3 5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.93929\tPrecision: 0.96748\tRecall: 0.59500\tF1: 0.73684\tF2: 0.64464\n",
      "\tTotal predictions: 1400\tTrue positives:  119\tFalse positives:    4\tFalse negatives:   81\tTrue negatives: 1196\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.94357\tPrecision: 0.98400\tRecall: 0.61500\tF1: 0.75692\tF2: 0.66486\n",
      "\tTotal predictions: 1400\tTrue positives:  123\tFalse positives:    2\tFalse negatives:   77\tTrue negatives: 1198\n",
      "\n",
      "=======================new best 0.756923076923 10 50 2 5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.95429\tPrecision: 0.97222\tRecall: 0.70000\tF1: 0.81395\tF2: 0.74153\n",
      "\tTotal predictions: 1400\tTrue positives:  140\tFalse positives:    4\tFalse negatives:   60\tTrue negatives: 1196\n",
      "\n",
      "=======================new best 0.813953488372 10 50 2 10\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.95857\tPrecision: 0.97973\tRecall: 0.72500\tF1: 0.83333\tF2: 0.76477\n",
      "\tTotal predictions: 1400\tTrue positives:  145\tFalse positives:    3\tFalse negatives:   55\tTrue negatives: 1197\n",
      "\n",
      "=======================new best 0.833333333333 10 50 3 5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.96071\tPrecision: 0.98013\tRecall: 0.74000\tF1: 0.84330\tF2: 0.77813\n",
      "\tTotal predictions: 1400\tTrue positives:  148\tFalse positives:    3\tFalse negatives:   52\tTrue negatives: 1197\n",
      "\n",
      "=======================new best 0.843304843305 10 50 3 10\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.94786\tPrecision: 0.96350\tRecall: 0.66000\tF1: 0.78338\tF2: 0.70438\n",
      "\tTotal predictions: 1400\tTrue positives:  132\tFalse positives:    5\tFalse negatives:   68\tTrue negatives: 1195\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.95429\tPrecision: 0.97887\tRecall: 0.69500\tF1: 0.81287\tF2: 0.73779\n",
      "\tTotal predictions: 1400\tTrue positives:  139\tFalse positives:    3\tFalse negatives:   61\tTrue negatives: 1197\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.95643\tPrecision: 0.93711\tRecall: 0.74500\tF1: 0.83008\tF2: 0.77685\n",
      "\tTotal predictions: 1400\tTrue positives:  149\tFalse positives:   10\tFalse negatives:   51\tTrue negatives: 1190\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.96071\tPrecision: 0.99320\tRecall: 0.73000\tF1: 0.84150\tF2: 0.77086\n",
      "\tTotal predictions: 1400\tTrue positives:  146\tFalse positives:    1\tFalse negatives:   54\tTrue negatives: 1199\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.98643\tPrecision: 0.96891\tRecall: 0.93500\tF1: 0.95165\tF2: 0.94159\n",
      "\tTotal predictions: 1400\tTrue positives:  187\tFalse positives:    6\tFalse negatives:   13\tTrue negatives: 1194\n",
      "\n",
      "=======================new best 0.95165394402 10 68 2 5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.97000\tPrecision: 0.97024\tRecall: 0.81500\tF1: 0.88587\tF2: 0.84194\n",
      "\tTotal predictions: 1400\tTrue positives:  163\tFalse positives:    5\tFalse negatives:   37\tTrue negatives: 1195\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.98357\tPrecision: 0.95385\tRecall: 0.93000\tF1: 0.94177\tF2: 0.93467\n",
      "\tTotal predictions: 1400\tTrue positives:  186\tFalse positives:    9\tFalse negatives:   14\tTrue negatives: 1191\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.97071\tPrecision: 0.97041\tRecall: 0.82000\tF1: 0.88889\tF2: 0.84623\n",
      "\tTotal predictions: 1400\tTrue positives:  164\tFalse positives:    5\tFalse negatives:   36\tTrue negatives: 1195\n",
      "\n",
      "{'rf_n_estimators': 5, 'pca_n_components': 68, 'selector_percentile': 10, 'rf_max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "### define searhc area\n",
    "param_grid = dict(pca_n_components=[40, 50, 60, 68],\n",
    "                  selector_percentile=[10],\n",
    "                  rf_max_depth=[2, 3],\n",
    "                  rf_n_estimators=[5, 10])\n",
    "### Accept a dictionary of parameter and find the best combination\n",
    "def GridSearcher(features_train_tfidf, labels_train_enconded, param_grid, base_f1=0):\n",
    "    for n in param_grid['pca_n_components']:\n",
    "        for p in param_grid['selector_percentile']:\n",
    "            for depth in param_grid['rf_max_depth']:\n",
    "                for estimator in param_grid['rf_n_estimators']:\n",
    "                    current_f1 = feature_selection_pipeline(features_train_tfidf,labels_train_enconded,p, n, depth, estimator)\n",
    "                    if current_f1 > base_f1:\n",
    "                        base_f1 = current_f1\n",
    "                        print \"=======================new best\", base_f1 , p, n, depth, estimator\n",
    "                        best_param = dict(pca_n_components=n,\n",
    "                                           selector_percentile=p,\n",
    "                                           rf_max_depth=depth,\n",
    "                                           rf_n_estimators=estimator)\n",
    "    return best_param\n",
    "\n",
    "\n",
    "best_combination = GridSearcher(features_train_tfidf, labels_train_enconded, param_grid, base_f1=0)\n",
    "print best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.98143\tPrecision: 1.00000\tRecall: 0.87000\tF1: 0.93048\tF2: 0.89322\n",
      "\tTotal predictions: 1400\tTrue positives:  174\tFalse positives:    0\tFalse negatives:   26\tTrue negatives: 1200\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.98643\tPrecision: 0.96891\tRecall: 0.93500\tF1: 0.95165\tF2: 0.94159\n",
      "\tTotal predictions: 1400\tTrue positives:  187\tFalse positives:    6\tFalse negatives:   13\tTrue negatives: 1194\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.97929\tPrecision: 1.00000\tRecall: 0.85500\tF1: 0.92183\tF2: 0.88054\n",
      "\tTotal predictions: 1400\tTrue positives:  171\tFalse positives:    0\tFalse negatives:   29\tTrue negatives: 1200\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.92571\tPrecision: 0.94444\tRecall: 0.51000\tF1: 0.66234\tF2: 0.56167\n",
      "\tTotal predictions: 1400\tTrue positives:  102\tFalse positives:    6\tFalse negatives:   98\tTrue negatives: 1194\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.91929\tPrecision: 0.94845\tRecall: 0.46000\tF1: 0.61953\tF2: 0.51282\n",
      "\tTotal predictions: 1400\tTrue positives:   92\tFalse positives:    5\tFalse negatives:  108\tTrue negatives: 1195\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.90714\tPrecision: 0.91667\tRecall: 0.38500\tF1: 0.54225\tF2: 0.43552\n",
      "\tTotal predictions: 1400\tTrue positives:   77\tFalse positives:    7\tFalse negatives:  123\tTrue negatives: 1193\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.88929\tPrecision: 0.79221\tRecall: 0.30500\tF1: 0.44043\tF2: 0.34778\n",
      "\tTotal predictions: 1400\tTrue positives:   61\tFalse positives:   16\tFalse negatives:  139\tTrue negatives: 1184\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.86214\tPrecision: 0.55932\tRecall: 0.16500\tF1: 0.25483\tF2: 0.19208\n",
      "\tTotal predictions: 1400\tTrue positives:   33\tFalse positives:   26\tFalse negatives:  167\tTrue negatives: 1174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Plot effect of change of percentile on f1 score:\n",
    "percentiles = [5, 10, 15, 20, 30, 40, 50, 80]\n",
    "f1_scores=[]\n",
    "for percentile in percentiles:\n",
    "    current_f1 = feature_selection_pipeline(features_train_tfidf,labels_train_enconded,percentile, 68, 2, 5)\n",
    "    f1_scores.append(current_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAF5CAYAAADQ2iM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164b4eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.plot(percentiles, f1_scores, '-bo')\n",
    "plt.xlabel('Percentile of tfidf data preserved')\n",
    "plt.ylabel('f1 score')\n",
    "pickle.dump([percentiles, f1_scores] , file('f1plot.pickle', 'w'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Perform feature selection on the tfidf dataset and \n",
    "### keep the most-important 10% of the data based on the pipeline.\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(features_train_tfidf, labels_train_enconded)\n",
    "features_train_selected = selector.transform(features_train_tfidf)\n",
    "features_test_selected  = selector.transform(features_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Perform PCA on the training data and transform both datasets\n",
    "### 68 was chosen due to the result of the pipeline\n",
    "pca = PCA(n_components=68)\n",
    "pca.fit(features_train_selected.toarray())\n",
    "features_train_selected = pca.transform(features_train_selected.toarray())\n",
    "features_test_selected = pca.transform(features_test_selected.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAF5CAYAAACBThBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ziAMTMzs8ZxAGNmZmaN8xRmLbuYvi8qvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bcf6e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Explained_variance\n",
      "0            0.015181\n",
      "1            0.014482\n",
      "2            0.014199\n",
      "3            0.013586\n",
      "4            0.013410\n",
      "5            0.012872\n",
      "6            0.012675\n",
      "7            0.012514\n",
      "8            0.009947\n",
      "9            0.008514\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(pca , file('pca.pickle', 'w'))\n",
    "plt.plot(pca.explained_variance_)\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.show()\n",
    "e_v = pd.DataFrame(pca.explained_variance_, columns=['Explained_variance'])\n",
    "pickle.dump(e_v , file('pca.pickle', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save the dataset(dict) as panda dataframes\n",
    "data_base_train_tfidf = pd.DataFrame(features_train_selected)\n",
    "data_base_test_tfidf = pd.DataFrame(features_test_selected)\n",
    "data_base_train_tfidf['email_address'] = labels_train\n",
    "data_base_test_tfidf['email_address'] = labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining email and financial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Split the financial data into training and test based on email addresses \n",
    "### available in the email data training and test\n",
    "database_numerical_train = database_numerical[database_numerical['email_address'].isin(data_base_train_tfidf['email_address'])]\n",
    "database_numerical_test = database_numerical[database_numerical['email_address'].isin(data_base_test_tfidf['email_address'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Set email address as unique identifier (index) for training and test \n",
    "### datasets of both email and financial dataframes.\n",
    "data_base_train_tfidf = data_base_train_tfidf.set_index(['email_address'])\n",
    "data_base_test_tfidf = data_base_test_tfidf.set_index(['email_address'])\n",
    "database_numerical_train = database_numerical_train.set_index(['email_address'])\n",
    "database_numerical_test = database_numerical_test.set_index(['email_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Join the training dataset of email (tfidf) and financial dataframes.\n",
    "## Join the test dataset of email (tfidf) and financial dataframes.\n",
    "database_train = database_numerical_train.join(data_base_train_tfidf)\n",
    "database_test = database_numerical_test.join(data_base_test_tfidf)\n",
    "\n",
    "### Construct a master dataset to write out the data from.\n",
    "whole_database = pd.concat([database_train,database_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Make the final feature list based on the columns in the master dataframe\n",
    "### and put poi as the first feature.\n",
    "features_list = list(whole_database.columns)\n",
    "features_list.remove('poi')\n",
    "features_list.insert(0,'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Construct a dictionary dataset from the master dataframe.\n",
    "keys = whole_database.index.values\n",
    "my_dataset={}\n",
    "for key in keys:\n",
    "    my_dataset[key]={}\n",
    "    for feature in features_list:\n",
    "        my_dataset[key][feature]=whole_database.loc[key, feature]\n",
    "        \n",
    "### Moving to our original training and test dataframes for the rest\n",
    "### of the analysis.\n",
    "keys_train = database_train.index.values\n",
    "my_train_dataset={}\n",
    "for key in keys_train:\n",
    "    my_train_dataset[key]={}\n",
    "    for feature in features_list:\n",
    "        my_train_dataset[key][feature]=database_train.loc[key, feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### preparing labels and features for sklearn\n",
    "train_labels = database_train['poi'].values\n",
    "test_labels = database_test['poi'].values\n",
    "database_train = database_train.drop('poi', axis=1).as_matrix()\n",
    "database_test = database_test.drop('poi', axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Scaling the features.\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(database_train)\n",
    "database_train = scaler.transform(database_train)\n",
    "database_test = scaler.transform(database_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Script to test the classifiers\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "#def main():\n",
    "#    ### load up student's classifier, dataset, and feature_list\n",
    "#    clf, dataset, feature_list = load_classifier_and_data()\n",
    "#    ### Run testing script\n",
    "#    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: GaussianNB(priors=None)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n",
      "Test accuracy:  0.222222222222\n",
      "Confusion matrix: \n",
      "[[ 0 14]\n",
      " [ 0  4]]\n",
      "Recall score is:  1.0\n",
      "Precision score is:  0.222222222222\n",
      "F1 score is:  0.363636363636\n"
     ]
    }
   ],
   "source": [
    "### Naive bayes\n",
    "clf_nb = GaussianNB()\n",
    "test_classifier(clf_nb, my_train_dataset, feature_list)\n",
    "clf_nb.fit(database_train, train_labels)\n",
    "#scoretr_nb = clf_nb.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \", scoretr_nb\n",
    "scorete_nb = clf_nb.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_nb\n",
    "pred_nb = clf_nb.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_nb)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_nb)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_nb)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "Recall score is:  0.75\n",
      "Precision score is:  0.428571428571\n",
      "F1 score is:  0.545454545455\n",
      "SVC(C=1e-06, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=5, gamma=1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=7, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "### Grid search support vectore machines\n",
    "parameters ={'kernel':('linear', 'rbf', 'sigmoid', 'poly'),\n",
    "             'C':[1e-22, 1e-8, 1e-6, 1e-4, 1e-2, 0.1, 1, 2],\n",
    "             'degree':[2, 3, 4, 5],\n",
    "             'gamma':[0.0001, 0.01, 0.05, 0.1, 0.2, 1, 2]}\n",
    "svm = SVC(random_state=7)\n",
    "clf_svm = GridSearchCV(svm, parameters)\n",
    "clf_svm.fit(database_train, train_labels)\n",
    "scoretr_svm = clf_svm.score(database_train, train_labels)\n",
    "print \"Training accuracy: \", scoretr_svm\n",
    "scorete_svm = clf_svm.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_svm\n",
    "pred_svm = clf_svm.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_svm)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_svm)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_svm)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_svm)\n",
    "print clf_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1e-06, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=5, gamma=1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=7, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\tAccuracy: 0.14286\tPrecision: 0.14286\tRecall: 1.00000\tF1: 0.25000\tF2: 0.45455\n",
      "\tTotal predictions: 7000\tTrue positives: 1000\tFalse positives: 6000\tFalse negatives:    0\tTrue negatives:    0\n",
      "\n",
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "Recall score is:  0.75\n",
      "Precision score is:  0.428571428571\n",
      "F1 score is:  0.545454545455\n"
     ]
    }
   ],
   "source": [
    "### Support vectore machines\n",
    "clf_svm = SVC(C=1e-06, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=None, degree=5, gamma=1, kernel='poly',\n",
    "  max_iter=-1, probability=False, random_state=7, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "test_classifier(clf_svm, my_train_dataset, feature_list)\n",
    "clf_svm.fit(database_train, train_labels)\n",
    "#scoretr_svm = clf_svm.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \", scoretr_svm\n",
    "scorete_svm = clf_svm.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_svm\n",
    "pred_svm = clf_svm.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_svm)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_svm)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_svm)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.985294117647\n",
      "Test accuracy:  0.833333333333\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 2  2]]\n",
      "Recall score is:  0.5\n",
      "Precision score is:  0.666666666667\n",
      "F1 score is:  0.571428571429\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=1, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "### Linear classifiers \n",
    "parameters ={'loss':('log', 'hinge'), 'penalty':('l2', 'l1', 'elasticnet'),\\\n",
    "             'alpha':[1e-8, 1e-4, 1e-2, 1e-1, 1, 10, 100, 100000]}\n",
    "sgd = SGDClassifier(random_state=1)\n",
    "clf_sgd = GridSearchCV(sgd, parameters)\n",
    "clf_sgd.fit(database_train, train_labels)\n",
    "scoretr_sgd = clf_sgd.score(database_train, train_labels)\n",
    "print \"Training accuracy: \",scoretr_sgd\n",
    "scorete_sgd = clf_sgd.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_sgd\n",
    "pred_sgd = clf_sgd.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_sgd)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_sgd)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_sgd)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_sgd)\n",
    "print clf_sgd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=1, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\tAccuracy: 0.21957\tPrecision: 0.14267\tRecall: 0.89100\tF1: 0.24596\tF2: 0.43485\n",
      "\tTotal predictions: 7000\tTrue positives:  891\tFalse positives: 5354\tFalse negatives:  109\tTrue negatives:  646\n",
      "\n",
      "Test accuracy:  0.833333333333\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 2  2]]\n",
      "Recall score is:  0.5\n",
      "Precision score is:  0.666666666667\n",
      "F1 score is:  0.571428571429\n"
     ]
    }
   ],
   "source": [
    "### SGD\n",
    "clf_sgd = SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
    "       penalty='l1', power_t=0.5, random_state=1, shuffle=True, verbose=0,\n",
    "       warm_start=False)\n",
    "test_classifier(clf_sgd, my_train_dataset, feature_list)\n",
    "clf_sgd.fit(database_train, train_labels)\n",
    "#scoretr_sgd = clf_sgd.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_sgd\n",
    "scorete_sgd = clf_sgd.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_sgd\n",
    "pred_sgd = clf_sgd.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_sgd)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_sgd)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_sgd)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.777777777778\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 3  1]]\n",
      "Recall score is:  0.25\n",
      "Precision score is:  0.5\n",
      "F1 score is:  0.333333333333\n",
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "### Linear regression\n",
    "parameters ={'C':[1e-22, 1e-8, 1e-6, 1e-4, 1e-2, 0.1, 1, 2, 4, 6]}\n",
    "lr = LogisticRegression()\n",
    "clf_lr = GridSearchCV(lr, parameters)\n",
    "clf_lr.fit(database_train, train_labels)\n",
    "scoretr_lr = clf_lr.score(database_train, train_labels)\n",
    "print \"Training accuracy: \",scoretr_lr\n",
    "scorete_lr = clf_lr.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_lr\n",
    "pred_lr = clf_lr.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_lr)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_lr)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_lr)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_lr)\n",
    "print clf_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n",
      "Test accuracy:  0.777777777778\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 3  1]]\n",
      "Recall score is:  0.25\n",
      "Precision score is:  0.5\n",
      "F1 score is:  0.333333333333\n"
     ]
    }
   ],
   "source": [
    "### Linear regression\n",
    "clf_lr = LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "test_classifier(clf_lr, my_train_dataset, feature_list)\n",
    "clf_lr.fit(database_train, train_labels)\n",
    "#scoretr_lr = clf_lr.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_lr\n",
    "scorete_lr = clf_lr.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_lr\n",
    "pred_lr = clf_lr.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_lr)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_lr)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_lr)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "Recall score is:  0.75\n",
      "Precision score is:  0.428571428571\n",
      "F1 score is:  0.545454545455\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.01, n_estimators=20, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "### Grid search to ada boost\n",
    "parameters ={'learning_rate':[0.001, 0.01, 0.1, 0.2, 0.5, 1 , 2], 'n_estimators':[5, 10, 20, 50]}\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "clf_ada = GridSearchCV(ada, parameters)\n",
    "clf_ada.fit(database_train, train_labels)\n",
    "#scoretr_rf = clf_ada.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_ada\n",
    "scorete_ada = clf_ada.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_ada\n",
    "pred_ada = clf_ada.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_ada)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_ada)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_ada)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_ada)\n",
    "print clf_ada.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.01, n_estimators=20, random_state=42)\n",
      "\tAccuracy: 0.95757\tPrecision: 0.82456\tRecall: 0.89300\tF1: 0.85742\tF2: 0.87842\n",
      "\tTotal predictions: 7000\tTrue positives:  893\tFalse positives:  190\tFalse negatives:  107\tTrue negatives: 5810\n",
      "\n",
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[10  4]\n",
      " [ 1  3]]\n",
      "Recall score is:  0.75\n",
      "Precision score is:  0.428571428571\n",
      "F1 score is:  0.545454545455\n"
     ]
    }
   ],
   "source": [
    "### Ada boost\n",
    "clf_ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.01, n_estimators=20, random_state=42)\n",
    "test_classifier(clf_ada, my_train_dataset, feature_list)\n",
    "clf_ada.fit(database_train, train_labels)\n",
    "#scoretr_ada = clf_ada.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_ada\n",
    "scorete_ada = clf_ada.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_ada\n",
    "pred_ada = clf_ada.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_ada)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_ada)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_ada)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.1 ,  0.  ,  0.25,  0.  ,  0.4 ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.25])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ada.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.777777777778\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "Recall score is:  0.0\n",
      "Precision score is:  0.0\n",
      "F1 score is:  0.0\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "### Decision tree\n",
    "parameters ={'min_samples_split':[2, 3, 4, 6]}\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "clf_dt = GridSearchCV(dt, parameters)\n",
    "clf_dt.fit(database_train, train_labels)\n",
    "scoretr_dt = clf_dt.score(database_train, train_labels)\n",
    "print \"Training accuracy: \",scoretr_dt\n",
    "scorete_dt = clf_dt.score(database_test, test_labels)\n",
    "print \"Test accuracy: \",scorete_dt\n",
    "pred_dt = clf_dt.predict(database_test)\n",
    "print \"Confusion matrix: \\n\",confusion_matrix(test_labels, pred_dt)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_dt)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_dt)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_dt)\n",
    "print clf_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.94371\tPrecision: 0.80422\tRecall: 0.80100\tF1: 0.80261\tF2: 0.80164\n",
      "\tTotal predictions: 7000\tTrue positives:  801\tFalse positives:  195\tFalse negatives:  199\tTrue negatives: 5805\n",
      "\n",
      "Test accuracy:  0.777777777778\n",
      "Confusion matrix: \n",
      "[[14  0]\n",
      " [ 4  0]]\n",
      "Recall score is:  0.0\n",
      "Precision score is:  0.0\n",
      "F1 score is:  0.0\n"
     ]
    }
   ],
   "source": [
    "### Decision tree\n",
    "clf_dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=1, splitter='best')\n",
    "test_classifier(clf_dt, my_train_dataset, feature_list)\n",
    "clf_dt.fit(database_train, train_labels)\n",
    "#scoretr_dt = clf_dt.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_dt\n",
    "scorete_dt = clf_dt.score(database_test, test_labels)\n",
    "print \"Test accuracy: \",scorete_dt\n",
    "pred_dt = clf_dt.predict(database_test)\n",
    "print \"Confusion matrix: \\n\",confusion_matrix(test_labels, pred_dt)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_dt)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_dt)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.11525424,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.88474576,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 4  0]]\n",
      "Recall score is:  0.0\n",
      "Precision score is:  0.0\n",
      "F1 score is:  0.0\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "### Grid search to optimize random forest\n",
    "parameters ={'max_depth':[2, 4, 6, 8, 10], 'n_estimators':[5, 10, 20, 50]}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf = GridSearchCV(rf, parameters)\n",
    "clf_rf.fit(database_train, train_labels)\n",
    "#scoretr_rf = clf_rf.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \",scoretr_rf\n",
    "scorete_rf = clf_rf.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_rf\n",
    "pred_rf = clf_rf.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_rf)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_rf)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_rf)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_rf)\n",
    "print clf_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.96429\tPrecision: 0.96758\tRecall: 0.77600\tF1: 0.86127\tF2: 0.80800\n",
      "\tTotal predictions: 7000\tTrue positives:  776\tFalse positives:   26\tFalse negatives:  224\tTrue negatives: 5974\n",
      "\n",
      "Test accuracy:  0.722222222222\n",
      "Confusion matrix: \n",
      "[[13  1]\n",
      " [ 4  0]]\n",
      "Recall score is:  0.0\n",
      "Precision score is:  0.0\n",
      "F1 score is:  0.0\n"
     ]
    }
   ],
   "source": [
    "### Random forest\n",
    "clf_rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
    "            verbose=0, warm_start=False)\n",
    "test_classifier(clf_rf, my_train_dataset, feature_list)\n",
    "clf_rf.fit(database_train, train_labels)\n",
    "#scoretr_rf = clf_rf.score(database_train, train_labels)\n",
    "#print \"Training accuracy: \", scoretr_rf\n",
    "scorete_rf = clf_rf.score(database_test, test_labels)\n",
    "print \"Test accuracy: \", scorete_rf\n",
    "pred_rf = clf_rf.predict(database_test)\n",
    "print \"Confusion matrix: \\n\", confusion_matrix(test_labels, pred_rf)\n",
    "print \"Recall score is: \", recall_score(test_labels, pred_rf)\n",
    "print \"Precision score is: \",precision_score(test_labels, pred_rf)\n",
    "print \"F1 score is: \",f1_score(test_labels, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.138322  ,  0.04533333,\n",
       "        0.        ,  0.05762712,  0.20405089,  0.35466667,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.01766234,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.18233766])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection\n",
    "Due to a relatively high F1 score and faster training and prediction time. The grid search decision tree was selected as the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesment\n",
    "Assesment of the model using the benchmark code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=5, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.94011\tPrecision: 0.89673\tRecall: 0.52100\tF1: 0.65908\tF2: 0.56865\n",
      "\tTotal predictions: 9000\tTrue positives:  521\tFalse positives:   60\tFalse negatives:  479\tTrue negatives: 7940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "clf, dataset, feature_list = load_classifier_and_data()\n",
    "### Run testing script\n",
    "test_classifier(clf, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "Some of the original features in the original dataset like 'email from poi to this person' or 'shared receipts with poi' are not constructed correctly since we are building a predictive model and there is no way to know if someone is a poi or not before investigation. Thankfully, my model did not use any of the financial data in the final random forest attempt as evident from the feature importance list.\n",
    "In addition, the benchmark code that measures accuracy of the model uses the both training and test data in the assesment, which is not the best practice.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
